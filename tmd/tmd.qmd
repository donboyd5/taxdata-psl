---
output: html_document
editor_options:
  chunk_output_type: console
---

# Analysis of tax microdata file (tmd)

## Setup

```{r}
#| label: includes
#| output: false

source(here::here("r", "libraries.r"))
# library(jsonlite)
# library(tidyjson)
library(naniar)

```

```{r}
#| label: constants-windows
#| output: false

# paths in the Windows part of my machine
# this project

tddir <- r"(E:\data\taxdata-psl)"
# tpath <- here::here("data", "potential_targets.csv")

targdir <- r"(E:\R_projects\projects\irs_targets\data)"
tpath <- fs::path(targdir, "potential_targets.rds")

# elsewhere in the windows part of my machine
pufdir <- r"(E:\data\puf_files\puf2015)"
ppath <- fs::path(pufdir, "puf_2015.csv")

```

```{r}
#| label: constants-linux
#| output: false

# Windows subsystem for linux (wsl) folders and filenames
wsldir <- "/\\wsl.localhost"
pydir <- "Ubuntu/home/donboyd5/Documents/python_projects"
tmddir <- "tax-microdata-benchmarking/tax_microdata_benchmarking/storage/output"
stor_path <- fs::path(wsldir, pydir, tmddir)
scratch_path <- fs::path(wsldir, pydir, "scratch")

```


```{r}
#| label: constants-ycuts

ycut19 <- c(-Inf, 1, 
            seq(5e3, 30e3, 5e3),
            40e3, 50e3, 75e3, 100e3,
            200e3, 500e3,
            1e6, 1.5e6, 2e6, 5e6, 10e6, Inf)

ycut22 <- c(-Inf, 
            seq(5e3, 60e3, 5e3),
            75e3, 100e3, 200e3, 500e3,
            1e6, 1.5e6, 2e6, 5e6, 10e6, Inf)

```



```{r}
#| label: constants
#| output: false


tab <- function(data, year, vname, title, scale=1, decimals=0){
  # create gt comparison table using a chosen variable
  
  tabdata <- data |> 
    filter(year==!!year, vname==!!vname) |> 
    select(incsort, incrange, file, nrecs, value) |> 
    arrange(incsort) |> 
    pivot_wider(names_from = file) |> 
    select(incsort, incrange, irs, tmd) |> 
    adorn_totals() |> 
    mutate(diff=tmd - irs,
           pdiff=diff / irs)
  
  tab <- tabdata |>
    gt() |>
    tab_header(title = html(title),
               subtitle = html(paste0(vname, " -- ", year))) |>
  fmt_number(columns=-c(incsort, incrange, contains("pdiff")),
             scale=scale,
             decimals=decimals) |>
  fmt_percent(columns=contains("pdiff"),
             scale=1,
             decimals=1)
  tab
}


tabtmd <- function(data, year, vname, title, scale=1, decimals=0){
  # create gt comparison table using a chosen variable
  
  tabdata <- data |> 
    filter(year==!!year, vname==!!vname) |> 
    select(incsort, incrange, tmdnrecs, irs, tmd) |> 
    arrange(incsort) |>
    adorn_totals() |> 
    mutate(diff=tmd - irs,
           pdiff=diff / irs)
  
  tab <- tabdata |>
    gt() |>
    tab_header(title = html(title),
               subtitle = html(paste0(vname, " -- ", year))) |>
    fmt_number(columns=c(irs, tmd, diff),
               scale=scale,
               decimals=decimals) |>
    fmt_number(columns=tmdnrecs,
               scale=1,
               decimals=0) |> 
    fmt_percent(columns=contains("pdiff"),
                scale=1,
                decimals=1)
  tab
}

```


## Get data mappings and definitions

Tax-Calculator variables.

```{r}
#| label: tax-calculator-variables
#| output: false

tcvars <- readRDS(here::here("data", "tcvars.rds")) # tax-calculator variables
# ht(tcvars)

# unique tax calculator variables (some variables ahve different info for different years)
utcvars <- tcvars |> 
  select(vname, desc) |> 
  distinct() |> 
  add_case(vname=c("n", "nret"), desc=c("# records", "# returns (millions)"))

```


PUF-IRS mapping.

```{r}
#| label: puf-irs-map
#| output: false

# targdir
# here::here("data", "target_recipes.xlsx")

pimap <- read_excel(fs::path(targdir, "target_recipes.xlsx"), 
                    sheet = "puf_irs_map",
                    range=cell_cols("E:H"),
                    skip=1) |> 
  filter(status=="good")


```

IRS targets.

```{r}
#| label: irs-targets
#| output: false

ptargets <- readRDS(tpath)
glimpse(ptargets)
count(ptargets, table)
ns(ptargets)
ptargets |> filter(table=="tab21", datatype=="filers") |> count(vname)
ptargets |> filter(table=="tab21", datatype=="filers") |> count(incsort, incrange)

```

### Make extended targets file with mapped names

```{r}
#| label: extended-targets
#| output: false

# get targets and proper names for variables we have mappings for

# prepare targets - I should have done it like this in the first place ----
# convert losses to negative numbers
count(ptargets, vname)
ptargets |> 
  filter(str_detect(vname, "loss"), incsort==1) |> 
  select(table, datatype, year, vname, ptarget)

ptargets2 <- ptargets |> 
  select(table, datatype, year, incsort, incrange, vname, ptarget) |> 
  mutate(irsvname=case_when(vname=="nret_all" ~ "nret_agi",
                         vname=="partnerinc" ~ "partnerpinc",
                         vname=="nret_hoh" ~ "nret_agi_hoh",
                         vname=="nret_mfjss" ~ "nret_agi_mfjss",
                         vname=="nret_mfs" ~ "nret_agi_mfs",
                         vname=="nret_single" ~ "nret_agi_single",
                         .default =  vname),
         vnbase=str_remove(irsvname, "nret_"),
         vtype=ifelse(str_starts(irsvname, "nret_"),
                      "nreturns",
                      "amount"),
         irsvname=paste0(vnbase, "_", vtype),
         ptarget=ifelse(vtype=="amount", ptarget * 1000, ptarget)
         ) |> 
  mutate(ptarget=ifelse(str_detect(vnbase, "loss") & vtype=="amount", ptarget * -1.0, ptarget)) |> 
  select(table, datatype, year, incsort, incrange, vnbase, vtype, irsvname, ptarget) |> 
  mutate(nranges=sum(incsort != 1), .by=c(table, datatype, year, vnbase, vtype, irsvname))

ptargets2
count(ptargets2, year, table, nranges)
count(ptargets2 |> filter(year==2021, datatype=="filers"), table, nranges)
count(ptargets2 |> filter(year==2021, datatype=="filers"), vnbase, vtype, irsvname)
# ptargets2 |> 
#   filter(str_detect(vnbase, "loss"), vtype=="amount", incsort==1) |> 
#   select(table, datatype, year, vnbase, vtype, ptarget)
# ptargets2 |> filter(nranges==0, year==2021)
# sum(incsort !=1)

ptargets2 |> 
  filter(year==2021, datatype=="filers") |> 
  select(vnbase, vtype, irsvname) |> 
  distinct() |> 
  pivot_wider(names_from = vtype, values_from = irsvname)

ptargets2 |> 
  filter(year==2021, datatype=="filers") |> 
  count(table)

ptargets2 |> 
  filter(incsort==1, vnbase=="agi", year==2021, datatype=="filers")

head(ptargets2)
count(ptargets2, irsvname, vnbase, vtype)

# prepare mapping of IRS names and puf/tmd names ----

pimap2 <- pimap |> 
  select(tmdname=puf_based_name, irsvname=irs_varname, puf_name) |> 
  mutate(vtype=ifelse(str_ends(tmdname, "_nnz"), "nreturns", "amount"),
         vnbase=str_remove(irsvname, "nret_"),
         irsvname=paste0(vnbase, "_", vtype))

# prepare extended targets df that we will match against tmd summaries ----
xtargets <- pimap2 |> 
  left_join(ptargets2 |>
              filter(year==2021, datatype=="filers"),
            by = join_by(irsvname, vtype, vnbase))
glimpse(xtargets)

count(xtargets, tmdname, vnbase, vtype)

## get a unique version of extended targets df, from first IRS table for a variable ----
uxtargets <- xtargets |> 
  group_by(year, tmdname, vtype, incsort) |> 
  arrange(table) |> 
  slice_head(n=1) |> 
  ungroup()
  
count(uxtargets, tmdname)
head(uxtargets)

```


## Compare multiple tmd files

## taxdata 2011 puf advanced to 2021 and put through Tax-Calculator

```{r}
#| label: get-tcoutput-data

# td21 is Martin's taxdata 2011 puf advanced to 2021 and put through Tax-Calculator in April
# td21_2024-07-18 is updated

# for taxdata, use fnbase tdtc2021 (me) or td21 (Martin)

# td21, taxdata

# td21_2024-07-18, taxdata_mh
# tdtc2021, taxdata_db

# fndf <- read_csv("
# fnbase,type                 
# td21_2024-07-18, taxdata
# pr148,
# pr148_pen.05,
# pr148_cggdist,
# pr148_bnpcggtpitssdist,
# ")

fndf <- read_csv("
fnbase,type                 
td21_2024-07-18, taxdata
pr150,
pr148_bnpcggtpitssdist,
pr150_bnpcggodpsitiitpitss,
")

fndf <- fndf |> 
  mutate(fname=case_when(
    str_detect(type, "taxdata") ~ paste0(fnbase, ".csv"),
    .default=paste0("tmd_2021_", fnbase, ".csv")),
    type=ifelse(is.na(type), fnbase, type))
fndf

f <- function(type, fname){
  print(fname)
  fpath <- fs::path(scratch_path, fname)
  df1 <- vroom(fpath)
  df2 <- df1 |> 
    mutate(type=type)
  df2
}

stack0 <- fndf |> 
  rowwise() |> 
  reframe(f(type, fname))

ns(stack0)
count(stack0, type)

original <- stack0 |> 
  filter(type=="pr150") |> 
  mutate(s006=s006_original,
         type="pr150_original")

stack <- bind_rows(stack0, original)
ns(stack)
count(stack, type)

stack |> 
  summarise(ctc=sum(ctc_total * s006), .by=c(type, data_source))

stack |> 
  summarise(n24=sum(n24 * s006), .by=c(type, data_source)) |> 
  pivot_wider(names_from = type, values_from = n24)

stack |> 
  mutate(ratio = s006 / s006_original) |> 
  filter(data_source==1) |> 
  summarise(ssd=sum((ratio - 1)^2), .by=type) |> 
  arrange(ssd)

```


```{r}
#| label: define-variables-to-analyze

idvars <- quos(type, data_source, RECID, s006, s006_original)
idvars_names <- sapply(idvars, as_name)

vars <- quos(c00100, c01000, c02500, c04800,
             e00200, e00300, e00400, e00600, e00650, e00900, 
             e01500, e02300, e02400,
             e17500, e18400, e18500)
vars_names <- sapply(vars, as_name)

```


```{r}
#| label: select-transform-long-stack

stack1 <- stack |> 
  select(!!!idvars, !!!vars) |> 
  mutate(c01000neg = (c01000 < 0)*c01000,
         c01000pos = (c01000 > 0)*c01000,
         e00900neg= (e00900 < 0)*e00900,
         e00900pos= (e00900 > 0)*e00900) |> 
  mutate(across(-any_of(idvars_names),
                ~(. != 0) * 1,
                .names = "{.col}_nnz"))
  

# TODO: nnz vars
  # mutate(across(any_of(vars),
  #        ~(. != 0) * 1,
  #        .names = "{.col}_nnz"))

long <- stack1 |> 
  mutate(ycut19=cut(c00100, ycut19, right=FALSE),
         incsort19=as.integer(ycut19) + 1L,
         ycut22=cut(c00100, ycut22, right=FALSE),
         incsort22=as.integer(ycut22) + 1L,) |> 
  pivot_longer(cols=-c(all_of(idvars_names), ycut19, incsort19, ycut22, incsort22)) |> 
  mutate(wvalue=value * s006) |> 
  relocate(s006, s006_original, .before = value)

ht(long)


```


```{r}
#| label: collapse-long


# collapsed by income range
collapse19 <- long |> 
  summarise(wvalue=sum(wvalue),
            .by=c(type, data_source, name, incsort19, ycut19)) |> 
  rename(incsort=incsort19, ycut=ycut19) |> 
  mutate(nranges=19)

collapse22 <- long |> 
  summarise(wvalue=sum(wvalue),
            .by=c(type, data_source, name, incsort22, ycut22)) |> 
  rename(incsort=incsort22, ycut=ycut22) |> 
  mutate(nranges=22)

# get totals by all but income range -- either collapse19 or collapse22 would work
collapsetots <- collapse19 |> 
  summarise(wvalue=sum(wvalue),
            .by=c(type, data_source, name)) |> 
  mutate(incsort=1)

# create a df that has all targets by 19 ranges and by 22 ranges
collapse <- bind_rows(
  collapse19,
  collapsetots |> mutate(nranges=19),
  collapse22,
  collapsetots |> mutate(nranges=22)) |> 
  mutate(ycut=as.character(ycut), # factor no longer meaningful as 2 different sets of cuts
         ycut=ifelse(is.na(ycut), "Total", ycut))
ht(collapse)
count(collapse, incsort, ycut)

# mutate(ycut19 = fct_na_value_to_level(ycut19, level = "Total"))

# we have different counts because data_sort==0 does not have records with high agi
count(collapse, data_source, incsort, ycut) 
count(collapse, type)
summary(collapse)
ns(collapse)

```


```{r}
#| label: add-targets

(y19vars <- uxtargets |> filter(year==2021, datatype=="filers", nranges==19) |> select(tmdname) |> distinct() |> pull(tmdname))
(y22vars <- uxtargets |> filter(year==2021, datatype=="filers", nranges==22) |> select(tmdname) |> distinct() |> pull(tmdname))

vis_miss(uxtargets)
vis_miss(uxtargets |> select(-puf_name))
count(uxtargets, tmdname)
summary(uxtargets)
head(collapse)
head(uxtargets)
count(uxtargets, vtype)

comp <- collapse |> 
  filter(data_source==1) |> 
  left_join(uxtargets |> 
              filter(datatype=="filers") |> 
              select(tmdname, irsvname, vtype, incsort, incrange, ptarget, nranges),
            join_by(incsort, nranges, name==tmdname),
            relationship = "many-to-many") |> 
  filter(!is.na(vtype)) |> # DJB temporary fix -- maybe a different kind of merge??
  mutate(diff=wvalue - ptarget,
         pdiff=diff / ptarget,
         absdiff=abs(diff),
         abspdiff=abs(pdiff),
         incrange=ifelse(is.na(incrange), ycut, incrange)) |> 
  select(nranges, type, tmdname=name, vtype, irsvname, incsort, incrange, ptarget, wvalue, diff, pdiff, absdiff, abspdiff)

count(comp, vtype)

```


## Examine datatable

```{css}
.dataTable {
  font-size: 12px;
}
```


```{r}
#| label: examine
#| column: page

# dollar_columns <- c("ptarget", "wvalue", "diff", "absdiff")
number_columns <- c("ptarget", "wvalue", "diff", "absdiff")

tab <- comp |> 
  # filter(!is.na(wvalue)) |> 
  # mutate(across(any_of(dollar_columns),
  #               \(x) ifelse(vtype=="amount", x / 1e9, x))) |> # $ billions
  # weightvar=factor(weightvar, levels=c("s006", "s006_original"), labels=c("s006_final", "s006_original")),
  # create factors so that they will appear in dropdown boxes
  mutate(incsort=factor(incsort),
         vtype=factor(vtype),
         type=factor(type),
         tmdname=factor(tmdname),
         irsvname=factor(irsvname),
         nranges=factor(nranges)) |> 
  # select(vtype, tmdname, incsort, incrange, ptarget:abspdiff) |> 
  mutate(across(any_of(number_columns),
                \(x) case_when(vtype=="amount" ~ label_comma(accuracy=.01, scale=1e-9)(x),
                               vtype=="nreturns" ~ label_comma(accuracy=1, scale=1)(x),
                               .default = "ERROR"))) |> 
  arrange(vtype, tmdname, incsort) |> 
  DT::datatable(rownames = FALSE,
            options = list(scrollX = TRUE, scrollY = '1800px', pageLength = 23), # autoWidth = TRUE, 
            caption = htmltools::tags$caption(
              style = 'caption-side: top; text-align: center;
              font-size: 25px; font-weight: bold;',
              '2021 filers (data_source==1); amounts are in $ billions; nreturns are numbers'
              ),
            width = "100%",
            filter="top") |>
    formatStyle(columns = number_columns, `text-align` = 'right') |> 
    # formatCurrency(columns = dollar_columns, currency="", digits=2) |>
    formatPercentage(columns = c("pdiff", "abspdiff"), digits = 1)

tab

```


## Weights

```{r}
#| label: comp-tmd-weights

df <- tmdcomp |> 
  filter(data_source==1) |> 
  select(tmd, RECID, s006, s006_original)

probs <- c(0, .05, .1, .25, .5, .75, .9, .95, 1)  

# penalty is .20
df |> 
  filter(data)
  mutate(ratio=s006 / s006_original) |> 
  summarise(x=quantile(ratio), .by = )


df |> 
  mutate(ratio=s006 / s006_original) |> 
  ggplot(aes(ratio)) +
  geom_histogram(bins = 60, fill = "blue", color = "black") +
  scale_y_continuous(labels = label_comma()) +
  scale_x_continuous(breaks = seq(0, 10, 1)) +
  facet_wrap(~tmd, ncol=1)

brks <- c(-1e3, -5e2, -1e2, 0, seq(100, 500, 100), 1e3, 5e3, 10e3)
df |> 
  mutate(change=s006 - s006_original) |> 
  ggplot(aes(change)) +
  geom_histogram(bins = 80, fill = "blue", color = "black") +
  scale_y_continuous(labels = label_comma()) +
  scale_x_continuous(breaks = brks) +
  facet_wrap(~tmd, ncol=1)

df |> 
  filter(str_detect(tmd, "issue126")) |> 
  mutate(ratio=s006 / s006_original) |> 
  ggplot(aes(ratio)) +
  geom_histogram(bins = 60, fill = "blue", color = "black") +
  scale_y_continuous(labels = label_comma()) +
  scale_x_continuous(breaks = seq(0, 10, 1))


df |> 
  filter(type=="masterpr139") |> 
  mutate(type="original", weight=s006_original) |> 
  bind_rows(df |> 
              rename(weight=s006)) |> 
  ggplot(aes(weight)) +
  geom_histogram(bins = 60, fill = "blue", color = "black") +
  scale_y_continuous(labels = label_comma()) +
  scale_x_continuous(breaks = seq(0, 20e3, 100), limits = c(0, 2000)) +
  facet_wrap(~tmd, ncol=1)

df |> 
  filter(type=="masterpr139") |> 
  mutate(type="original", weight=s006_original) |> 
  bind_rows(df |> 
              rename(weight=s006)) |> 
  ggplot(aes(weight)) +
  geom_histogram(bins = 60, fill = "blue", color = "black") +
  scale_y_continuous(labels = label_comma()) +
  scale_x_log10(breaks=c(0, 1, 10, 100, 1000, 10e3, 100e3), labels = label_comma()) +
  facet_wrap(~tmd, ncol=1)



df |> 
  mutate(ratio=s006 / s006_original) |> 
  summarise(x=quantile(ratio, probs=probs) |> list(), .by=tmd) |> 
  unnest_wider(col=x) |> 
  pivot_longer(-tmd, names_to = "quantile") |> 
  pivot_wider(names_from = tmd) |> 
  gt() |> 
  tab_header(title = "Quantiles of: s006 / s006_original") |>
  fmt_number(columns = -quantile,
             decimals = 3)
  
df |> 
  mutate(diff=s006 - s006_original) |> 
  summarise(x=quantile(diff, probs=probs) |> list(), .by=tmd) |> 
  unnest_wider(col=x) |> 
  pivot_longer(-tmd, names_to = "quantile") |> 
  pivot_wider(names_from = tmd) |> 
  gt() |> 
  tab_header(title = "Quantiles of: s006 - s006_original") |>
  fmt_number(columns = -quantile,
             decimals = 1)
  
(wcuts <- c(0, 10, 100, seq(100, 500, 100), seq(500, 2000, 500), seq(2e3, 5e3, 1e3), 10e3) |> unique())

df |> 
  mutate(change=s006 - s006_original,
         ratio=change / s006_original,
         wsize=cut(s006_original, wcuts)) |> 
  summarise(n=n(),
            change_min=min(change),
            change_p25=p25(change),
            change_p50=p50(change),
            change_p75=p75(change),
            change_max=max(change),
            ratio_p50=p50(ratio),
            .by=c(wsize, tmd)) |> 
  arrange(wsize, desc(tmd)) |> 
  select(wsize, tmd, n, value=ratio_p50) |> 
  pivot_wider(names_from = tmd) |> 
  gt() |> 
  tab_header(title = "Change in weight by size of original weight") |>
  fmt_number(columns = -c(wsize),
             decimals = 2)

df |> 
  mutate(change=s006 - s006_original,
         ratio=s006 / s006_original,
         wsize=cut(s006_original, wcuts)) |> 
  summarise(n=n(),
            change_min=min(change),
            change_p25=p25(change),
            change_p50=p50(change),
            change_p75=p75(change),
            change_max=max(change),
            ratio_p25=p25(ratio),
            ratio_p50=p50(ratio),
            ratio_p75=p75(ratio),
            .by=c(wsize, tmd)) |> 
  arrange(wsize, desc(tmd)) |> 
  select(wsize, tmd, n, value=ratio_p25) |> 
  pivot_wider(names_from = tmd) |> 
  gt() |> 
  tab_header(title = "Weight ratio by size of original weight") |>
  fmt_number(columns = n,
             decimals = 0) |> 
  fmt_number(columns = -c(wsize, n),
             decimals = 3)




df |> 
  mutate(change=s006 - s006_original,
         pctchange=change / s006_original,
         wsize=cut(s006_original, wcuts)) |> 
  summarise(n=n(),
            change_min=min(change),
            change_p25=p25(change),
            change_p50=p50(change),
            change_p75=p75(change),
            change_max=max(change),
            .by=c(wsize, tmd)) |> 
  arrange(wsize, desc(tmd)) |> 
  gt() |> 
  tab_header(title = "Change in weight by size of original weight") |>
  fmt_number(columns = -c(wsize, tmd),
             decimals = 1)

df |> 
  mutate(ratio=s006 / s006_original,
         wsize=cut(s006_original, wcuts)) |> 
  summarise(n=n(),
            ratio_min=min(ratio),
            ratio_p25=p25(ratio),
            ratio_p50=p50(ratio),
            ratio_p75=p75(ratio),
            ratio_max=max(ratio),
            .by=c(wsize, tmd)) |> 
  arrange(wsize, desc(tmd)) |> 
  gt() |> 
  tab_header(
    title = "Ratio of new weight to original weight by size of original weight"
  ) |>
  fmt_number(columns = -c(wsize, tmd),
             decimals = 2)


```


## Selected aggregates

```{r}

ns(tmdcomp)

uxtargets

# targets_collapse <- 


vars <- quos(c00100, e00200, e00900, e18400, e18500)

df <- tmdcomp |> 
  select(tmd, data_source, RECID, s006, s006_original, !!!vars) |> 
  mutate(e00900pos=(e00900 > 0)*e00900,
         e00900neg=(e00900 < 0)*e00900)

df2 <- df |> 
  mutate(nret=1) |> 
  pivot_longer(-c(tmd, data_source, RECID, s006, s006_original),
               names_to = "vname") |> 
  pivot_longer(starts_with("s006"),
               names_to = "weightvar",
               values_to = "weight")

df3 <- df2 |> 
  filter(data_source==1) |> 
  mutate(wtdvalue=value * weight) |> 
  summarise(wtdvalue=sum(wtdvalue),
            .by=c(weightvar, vname, tmd))

df4 <- df3 |> 
  left_join(uxtargets |> 
              filter(year==2021, incsort==1, !is.na(ptarget)) |> 
              select(tmdname, irsvname, ptarget),
            by=join_by(vname == tmdname)) |> 
  relocate(irsvname, .after = vname) |> 
  relocate(ptarget, .after = tmd) |> 
  mutate(diff=wtdvalue - ptarget,
         pdiff=diff / ptarget)


df4 |> 
  filter(weightvar=="s006", !is.na(ptarget)) |> 
  select(vname, irsvname, tmd, ptarget, diff, pdiff) |> 
  pivot_wider(names_from =tmd, values_from = c(diff, pdiff)) |> 
  gt() |> 
  fmt_number(columns = -c(vname, irsvname, contains("pdiff")),
             scale=1e-9,
             decimals=2) |> 
  fmt_percent(columns = contains("pdiff"),
             scale=1,
             decimals=1)  


# closeAllConnections()

# df |> 
#   filter(data_source==1) |>
#   summarise(across(
#     -c(data_source, RECID, s006, s006_original),
#     \(x) sum(x * s006)),
#     .by=tmd)


```




# Older

```{r}
#| label: ctc-exploration

df2 <- tmdtc2021 |> 
  select(RECID, data_source, s006, s006_original, c00100, n24, nu06, nu13, nu18)
summary(df2)

df2 |>
  select(-c00100) |> 
  pivot_longer(-c(RECID, data_source, s006, s006_original)) |> 
  summarise(s006_original=sum(value * s006_original),
            s006=sum(value * s006),
            .by=name) |> 
  mutate(diff=s006 - s006_original, pdiff=diff / s006_original) |>
  left_join(utcvars |> select(name=vname, desc),
            by = join_by(name)) |> 
  gt() |> 
  fmt_number(columns=s006_original:diff,
             scale=1e-6) |> 
  fmt_percent(columns=pdiff,
              decimals = 1)

```




```{r}
#| label: prepare-tmd_2021.csv
#| output: false

# ycuts ----
ycut19 <- c(-Inf, 1, 
            seq(5e3, 30e3, 5e3),
            40e3, 50e3, 75e3, 100e3,
            200e3, 500e3,
            1e6, 1.5e6, 2e6, 5e6, 10e6, Inf)

ycut22 <- c(-Inf, 
            seq(5e3, 60e3, 5e3),
            75e3, 100e3, 200e3, 500e3,
            1e6, 1.5e6, 2e6, 5e6, 10e6, Inf)

# ycut19: filers tab11, tab12, tab14
# ycut22: filers tab21

# y19filertabs <- c("tab11", "tab12", "tab14")
# y22filertabs <- c("tab21")


# c00100, c01000, c02500, c04800, e00200, e00300, e00400, e00600, e00900, e01500, e02400, mars1, mars2, mars3, mars4

# count(xtargets, tmdname, vtype)

ns(tmdtc2021)
glimpse(tmdtc2021)
summary(tmdtc2021 |> select(any_of(ns(tmdtc2021))))

vars <- c("c00100", "c01000neg", "c01000pos", "c02500", "c04800", "e00200", "e00300", "e00400", "e00600",
          "e00900neg", "e00900pos",
          "e01500", "e02300", "e02400",
          "e17500", "e18400")

tmd2 <- tmdtc2021 |>
  lcnames()|>
  filter(data_source==1) |>
  mutate(ycut19=cut(c00100, ycut19, right=FALSE),
         incsort19=as.integer(ycut19) + 1L,
         ycut22=cut(c00100, ycut22, right=FALSE),
         incsort22=as.integer(ycut22) + 1L) |>  # incsort will match with targets file
  mutate(c01000neg = c01000 * (c01000 < 0),
         c01000pos = c01000 * (c01000 > 0)) |> 
  mutate(e00900neg = e00900 * (e00900 < 0),
         e00900pos = e00900 * (e00900 > 0)) |> 
  select(s006, s006_original, incsort19, ycut19, incsort22, ycut22, any_of(vars)) |> 
  mutate(across(any_of(vars),
                ~(. != 0) * 1,
                .names = "{.col}_nnz"))
ht(tmd2)
ns(tmd2)
summary(tmd2)

# get summaries for y19 and y22 vars
ptargets2 |> filter(year==2021, datatype=="filers", nranges==23) |> select(irsvname) |> distinct() |> pull(irsvname)
count(uxtargets, tmdname)
count(xtargets, tmdname)
(y19vars <- uxtargets |> filter(year==2021, datatype=="filers", nranges==20) |> select(tmdname) |> distinct() |> pull(tmdname))
(y22vars <- uxtargets |> filter(year==2021, datatype=="filers", nranges==23) |> select(tmdname) |> distinct() |> pull(tmdname))

tmd_ycut19 <- tmd2 |>
  select(-c(ycut22, incsort22)) |> 
  rename(ycut=ycut19, incsort=incsort19) |> 
  pivot_longer(-c(ycut, incsort, s006, s006_original),
               names_to = "tmdname") |> 
  pivot_longer(c(s006, s006_original), names_to = "weightvar", values_to = "weight") |> 
  summarise(value=sum(value * weight), .by=c(tmdname, incsort, weightvar)) |> 
  mutate(nranges=19)

glimpse(tmd_ycut19)
count(tmd_ycut19, incsort)
count(tmd_ycut19, tmdname)

tmd_ycut22 <- tmd2 |> 
  select(-c(ycut19, incsort19)) |> 
  rename(ycut=ycut22, incsort=incsort22) |> 
  pivot_longer(-c(ycut, incsort, s006, s006_original),
               names_to = "tmdname") |> 
  pivot_longer(c(s006, s006_original), names_to = "weightvar", values_to = "weight") |> 
  summarise(value=sum(value * weight), .by=c(tmdname, incsort, weightvar)) |> 
  mutate(nranges=22)

glimpse(tmd_ycut22)
count(tmd_ycut22, incsort)
count(tmd_ycut22, tmdname)

tmd_ycut <- bind_rows(tmd_ycut19, tmd_ycut22)

sums_ycut <- tmd_ycut |> 
  summarise(value=sum(value), .by=c(weightvar, tmdname, nranges)) |> 
  mutate(incsort=1)

sums_ycut |> filter(tmdname=="c00100")

tmd4 <- bind_rows(tmd_ycut, sums_ycut) |> 
  mutate(year=2021, datatype="filers")
tmd4
ns(tmd4)
count(tmd4, tmdname)
count(uxtargets, tmdname, table)

count(tmd4, nranges)
count(uxtargets, nranges)

```


### Create comparison file

```{r}
#| label: comp-file
#| output: false

comp <- tmd4 |> 
  inner_join(uxtargets,
            by = join_by(tmdname, incsort, year, datatype, nranges)) |> 
  select(contains("name"), vnbase, datatype, vtype, table, weightvar, nranges, incsort, incrange, ptarget, value) |> 
  mutate(diff=value - ptarget,
         pdiff=diff / ptarget,
         absdiff=abs(diff),
         abspdiff=abs(pdiff)) |> 
  arrange(tmdname, datatype, table, weightvar, nranges, incsort)

comp
count(comp, nranges)
count(comp, tmdname)
head(comp)

```


### Examine results

```{r}
#| label: examine
#| column: page

dollar_columns <- c("ptarget", "value", "diff", "absdiff")

tab <- comp |> 
  mutate(across(any_of(dollar_columns),
                \(x) ifelse(vtype=="amount", x / 1e9, x))) |> # $ billions
  mutate(weightvar=factor(weightvar), # weightvar=factor(weightvar, levels=c("s006", "s006_original"), labels=c("s006_final", "s006_original")),
         incsort=factor(incsort),
         vtype=factor(vtype),
         vnbase=factor(vnbase)) |> 
  select(weightvar, vtype, vnbase, tmdname, incsort, incrange, ptarget:abspdiff) |> 
  arrange(weightvar, vtype, vnbase, tmdname, incsort) |> 
  DT::datatable(rownames = FALSE,
            options = list(scrollX = TRUE, scrollY = '1800px', pageLength = 23), # autoWidth = TRUE, 
            caption = htmltools::tags$caption(
              style = 'caption-side: top; text-align: center;
              font-size: 25px; font-weight: bold;',
              '2021 filers (data_source==1); amounts are in $ billions; nreturns are numbers'
              ),
            width = "100%",
            filter="top") |>
    formatCurrency(columns = dollar_columns, currency="", digits=2) |>
    formatPercentage(columns = c("pdiff", "abspdiff"), digits = 1)

tab

```


## Examine weights
```{r}
#| label: examine-weights

glimpse(tmd2)
ns(tmd2)

ratios <- tmd2 |> 
  mutate(ratio=s006 / s006_original)
summary(ratios)

cuts <- c(-Inf, 0, 10e3, 50e3, 100e3, 1e6, 10e6, 20e6, Inf)

ratios |> 
  mutate(ycut=cut(c00100, cuts)) |> 
  ggplot(aes(x=ycut, y=ratio)) + 
  geom_boxplot() +
  geom_hline(yintercept = 1, colour="blue") +
  geom_hline(yintercept = median(ratios$ratio), colour="red") +
  scale_y_continuous(breaks=seq(0, 10, .25))

ratios |> 
  mutate(ycut=cut(c00100, cuts)) |> 
  summarise(p25=p25(ratio),
            p50=p50(ratio),
            p75=p75(ratio), .by = ycut) |> 
  pivot_longer(-ycut) |> 
  filter(name=="p50") |> 
  ggplot(aes(x=ycut, y=value, colour=name)) +
  geom_point() +
  geom_line(aes(group=1)) +
  geom_hline()
  


```




<!-- ### Treatment of aggregate records -->

<!-- Here is what the 2015 PUF documentation (p.3) says about aggregate records: -->

<!-- ![](images/clipboard-2840902240.png) -->

<!-- I had raised concerns about the importance of these records - capital gains, in particular, are disproportionately large on one of these records â€“ and said that I think we should explore in the future whether there is information in these 4 records that we can use. However, for purposes of the current project we agreed - as other modelers using previous PUFs had done - that the proper and conservative approach for now is to exclude these records from our tmd files. We can revisit in the future whether there are ways we can use information from these records to improve upon our simple rule of excluding them. -->

<!-- However, these 4 records nonetheless appear to be in our tmd files. The table below shows, for tmd_2021.csv: -->

<!-- -   RECID for the 4 aggregate records -->
<!-- -   tmd values in 2021 for s006 (our final weight), c00100 (AGI, calculated), c01000 (net capital gains, calculated), and taxbc (tax before credits), each with _tmd suffix, -->
<!-- -   weighted values for the tmd c00100 and c01000 variables, with wtd_ prefix (weighted by s006_tmd) -->
<!-- -   raw puf values in 2015 for e00100 (AGI) and e00100 (net capital gains), with _puf suffix -->
<!-- -   I do not show original puf weights or pre-optimization tmd weights because the changes were not significant enough to be concerning -->

<!-- A few observations: -->

<!-- -   First and foremost, we don't want the 4 aggregate records in our output file and should remove them. -->
<!-- -   The extraordinary nature of these records is worth remembering: for example, RECID 999999 has average AGI of \$369.3 million, and weighted capital gains are \$111 billion (out of about \$2 trillion). -->
<!-- -   That certainly means these 4 records will have thrown off our optimized reweighting significantly and it will be important to see how things change after we remove them. -->
<!-- -   Strange things have happened to these records as we moved from the raw 2015 puf to the extrapolated (uprated), reweighted tmd file for 2021. For example, raw 2015 AGI (e00100) on RECID 999996 changed from -\$96.4 million to calculated AGI in 2021 of \$11.1 million. That may be just fine - it may be Tax-Calculator doing what it should be doing. We don't have to worry about it for these records but we do need to ask ourselves whether it suggests anything strange is going on that we should worry about for the other 225k records we have. I don't have anything particular I'm worried about, it's just an observation that I think we need to think about. -->

<!--  Seems like it would be a good idea to have a test for whether aggregate records are included. -->

